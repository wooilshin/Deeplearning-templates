{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b9c6dc-e25e-4acc-950d-7219b82897bc",
   "metadata": {},
   "source": [
    "<h1>Design Patterns for ML projects</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6330af83-2a07-4550-a5d6-098ca50c0b65",
   "metadata": {},
   "source": [
    "<h2>1.Reusable Training loop ('train' method in 'trainer.py')</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162d576-b943-479e-b34b-8c9edc12c2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, loss_fn, dataloader, epochs):  \n",
    "    for epoch in range(epochs):                     # epoch loop\n",
    "        for inputs, targets in dataloader:          # batch loop\n",
    "            optimizer.zero_grad()                     # clears the gradients from previous batch\n",
    "            outputs = model(inputs)                   # forward pass\n",
    "            loss = loss_fn(outputs, targets)          # compute loss\n",
    "            loss.backward()                           # back propagation\n",
    "            optimizer.step()                          # update params\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "train_loop(model, optimizer, loss_fn, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281f2c6-6d3d-41b3-85c3-891ac7941922",
   "metadata": {},
   "source": [
    "<h2>2.Design Patterns</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ffd11-b9b0-4958-9d1f-190edaa0b083",
   "metadata": {},
   "source": [
    "<h3>(1) Decorator (train.py)</h3>\n",
    "    \n",
    "<h7> Decorator adds logging functionality without modifying the core training code, keeping the code modular and clean.\n",
    "In this example this is done by simplely adding @log_training above the train_loop function. </h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c070f-0b67-461a-bda2-c99f8386971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def log_training(func):\n",
    "    def wrapper(*args, **kwargs):       # **kwargs (keyword arguments captures the key-value pairs)\n",
    "        start_time = time.time()\n",
    "        print(f\"Starting training: {func.__name__}...\")\n",
    "        \n",
    "        result = func(*args, **kwargs)  # Call actual training function\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Completed training: {func.__name__}. Time taken: {end_time - start_time:.2f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@log_training                          # this wraps the original function 'train_loop' with 'log_training'\n",
    "def train_loop(model, optimizer, loss_fn, dataloader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for inputs, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Assuming model, optimizer, loss_fn, and dataloader are predefined\n",
    "train_loop(model, optimizer, loss_fn, dataloader, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae73e6c-78e4-4f0a-8325-5e499e372c89",
   "metadata": {},
   "source": [
    "<h3>(3) Facade pattern (trainer.py)</h3>\n",
    "    \n",
    "<h7> Facade builds end-to-end pipelines for ML models, hiding the intricacy of each component (data loading, feature engineering, model training, evaluation) \n",
    "     </h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3377d3ae-c067-4cd8-ab34-0af0cf7d64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:                             # Load data \n",
    "    def load_data(self):\n",
    "        print(\"Loading data\")\n",
    "\n",
    "class Preprocessor:                           # Process data \n",
    "    def preprocess_data(self, data):\n",
    "        print(\"Preprocessing data\")\n",
    "\n",
    "class ModelTrainer:                           # Train model \n",
    "    def train_model(self, processed_data):\n",
    "        print(\"Training model\")\n",
    "\n",
    "\n",
    "class ModelPipelineFacade:                    # pipeline\n",
    "    def __init__(self):\n",
    "        self.data_loader = DataLoader()\n",
    "        self.preprocessor = Preprocessor()\n",
    "        self.trainer = ModelTrainer()\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        data = self.data_loader.load_data()\n",
    "        processed_data = self.preprocessor.preprocess_data(data)\n",
    "        model = self.trainer.train_model(processed_data)\n",
    "        print(\"Pipeline complete\")\n",
    "\n",
    "# Usage\n",
    "pipeline = ModelPipelineFacade()\n",
    "pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91c169-74f3-46bd-87e5-f432e9d6dc5e",
   "metadata": {},
   "source": [
    "<h3>(4) Builder pattern (model.py)</h3>\n",
    "    \n",
    "<h7> Constructs a complex object (like a neural network architecture) step-by-step, allowing for flexible and customizable configurations.\n",
    "     </h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32792527-18b0-4504-abe9-12cb3d753575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ModelBuilder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelBuilder, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "    def add_layer(self, units, activation=None):\n",
    "        if not hasattr(self, 'input_shape'):\n",
    "            raise ValueError(\"You need to set input shape first with `set_input_shape`\")\n",
    "\n",
    "        # fully connected layer\n",
    "        self.layers.append(nn.Linear(self.input_shape, units))\n",
    "\n",
    "        # activation function\n",
    "        if activation:\n",
    "            self.layers.append(getattr(nn, activation)())\n",
    "\n",
    "        # input shape for the next layer\n",
    "        self.input_shape = units\n",
    "        return self\n",
    "\n",
    "    def set_input_shape(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        return self\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# Usage\n",
    "model = (ModelBuilder()\n",
    "         .set_input_shape(28 * 28)  # Setting input shape for flattened 28x28 images\n",
    "         .add_layer(128, 'ReLU')     # Adding hidden layer\n",
    "         .add_layer(10, 'Softmax'))  # Adding output layer with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f5b33-1442-43e3-8738-6cae820bec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3>(5) Observer pattern </h3>\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

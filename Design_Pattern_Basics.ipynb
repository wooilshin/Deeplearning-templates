{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b9c6dc-e25e-4acc-950d-7219b82897bc",
   "metadata": {},
   "source": [
    "<h1>Design Patterns for ML projects</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349c05d-61e2-4bbe-bdae-66fd493fac56",
   "metadata": {},
   "source": [
    "<h2>(1) Builder pattern (model.py)</h2>\n",
    "    \n",
    "<h7> Constructs a complex object (like a neural network architecture) step-by-step, allowing for flexible and customizable configurations.\n",
    "     </h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91779e-84be-49fc-a876-ea5805d82810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ModelBuilder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModelBuilder, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.input_shape = None  # Initialize input shape as None\n",
    "\n",
    "    def add_layer(self, units, activation=None):\n",
    "        if self.input_shape is None:\n",
    "            raise ValueError(\"Input shape not set. Use set_input_shape before adding layers.\")\n",
    "\n",
    "        # Adding a fully connected layer\n",
    "        self.layers.append(nn.Linear(self.input_shape, units))\n",
    "        \n",
    "        # If activation is provided, use the activation function\n",
    "        if activation:\n",
    "            self.layers.append(getattr(nn, activation)())\n",
    "\n",
    "        # Update input shape for the next layer\n",
    "        self.input_shape = units\n",
    "        return self\n",
    "\n",
    "    def set_input_shape(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        return self\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# Usage\n",
    "model = (ModelBuilder()\n",
    "         .set_input_shape(28 * 28)  # Setting input shape for flattened 28x28 images\n",
    "         .add_layer(128, 'ReLU')     # Adding hidden layer\n",
    "         .add_layer(10, 'Softmax'))  # Adding output layer with softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c03bc-5756-4b4d-b35c-3b7cf6a150f6",
   "metadata": {},
   "source": [
    "<h2> (2) Reusable Training loop </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb77365-8b71-4bc8-91db-0f0eaaa58bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, loss_fn, dataloader, epochs):  \n",
    "    for epoch in range(epochs):                     # epoch loop\n",
    "        for inputs, targets in dataloader:          # batch loop\n",
    "            optimizer.zero_grad()                     # clears the gradients from previous batch\n",
    "            outputs = model(inputs)                   # forward pass\n",
    "            loss = loss_fn(outputs, targets)          # compute loss\n",
    "            loss.backward()                           # back propagation\n",
    "            optimizer.step()                          # update params\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "train_loop(model, optimizer, loss_fn, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ffd11-b9b0-4958-9d1f-190edaa0b083",
   "metadata": {},
   "source": [
    "<h2> (3) Decorator pattern </h2>\n",
    "\n",
    "<h7> Build a wrapper around a function in a modular and clean fashion.</h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c070f-0b67-461a-bda2-c99f8386971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of wrapper around a function. Apply a wrapper around a class is also possible.\n",
    "\n",
    "import time\n",
    "\n",
    "def log_training(func):\n",
    "    def wrapper(*args, **kwargs):       # **kwargs (keyword arguments captures the key-value pairs)\n",
    "        start_time = time.time()\n",
    "        print(f\"Starting training: {func.__name__}...\")\n",
    "        \n",
    "        result = func(*args, **kwargs)  # Call actual training function\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Completed training: {func.__name__}. Time taken: {end_time - start_time:.2f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@log_training                          # this wraps the original function 'train_loop' with 'log_training'\n",
    "def train_loop(model, optimizer, loss_fn, dataloader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for inputs, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Assuming model, optimizer, loss_fn, and dataloader are predefined\n",
    "train_loop(model, optimizer, loss_fn, dataloader, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae73e6c-78e4-4f0a-8325-5e499e372c89",
   "metadata": {},
   "source": [
    "<h2>(4) Facade pattern </h2>\n",
    "    \n",
    "<h7> Facade builds end-to-end pipelines for ML models, hiding the intricacy of each component (data loading, feature engineering, model training, evaluation) \n",
    "     </h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5728dc8-35c8-41f1-b069-ab56e6bdf070",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def load_data(self):\n",
    "        data = \"raw_data\"  # Placeholder for actual data\n",
    "        return data\n",
    "\n",
    "class Preprocessor:\n",
    "    def preprocess_data(self, data):\n",
    "        processed_data = \"processed_data\"  # Placeholder for actual processed data\n",
    "        return processed_data\n",
    "\n",
    "class ModelTrainer:\n",
    "    def train_loop(self, model, optimizer, loss_fn, dataloader, epochs):\n",
    "        for epoch in range(epochs):                     # epoch loop\n",
    "            for inputs, targets in dataloader:          # batch loop\n",
    "                optimizer.zero_grad()                   # clears gradients from previous batch\n",
    "                outputs = model(inputs)                 # forward pass\n",
    "                loss = loss_fn(outputs, targets)        # compute loss\n",
    "                loss.backward()                         # backpropagation\n",
    "                optimizer.step()                        # update parameters\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "        print(\"Training complete\")\n",
    "        return model\n",
    "\n",
    "class ModelPipelineFacade:\n",
    "    def __init__(self, model, optimizer, loss_fn, dataloader, epochs=10):\n",
    "        self.data_loader = DataLoader()\n",
    "        self.preprocessor = Preprocessor()\n",
    "        self.trainer = ModelTrainer()\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.dataloader = dataloader\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        # Step 1: Load data\n",
    "        data = self.data_loader.load_data()\n",
    "        \n",
    "        # Step 2: Preprocess data\n",
    "        processed_data = self.preprocessor.preprocess_data(data)\n",
    "        \n",
    "        # Step 3: Train model\n",
    "        trained_model = self.trainer.train_loop(\n",
    "            self.model, self.optimizer, self.loss_fn, self.dataloader, self.epochs\n",
    "        )\n",
    "        \n",
    "        print(\"Pipeline complete\")\n",
    "        return trained_model\n",
    "\n",
    "# Usage\n",
    "pipeline = ModelPipelineFacade(model, optimizer, loss_fn, train_loader, epochs=10)\n",
    "pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32792527-18b0-4504-abe9-12cb3d753575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7e23b0-36ab-4075-8e86-7a5f23647c3a",
   "metadata": {},
   "source": [
    "<h3>(5) Observer pattern </h3>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035f62f-42b0-4e33-a081-9de4df1a3b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
